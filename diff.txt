50,85d49
< #include "precomp.hpp"
< #include <unistd.h>
< #include <string.h>
< #include <gst/gst.h>
< #include <gst/gstbuffer.h>
< #include <gst/video/video.h>
< #include <gst/app/gstappsink.h>
< #include <gst/app/gstappsrc.h>
< #include <gst/riff/riff-media.h>
< #include <gst/pbutils/missing-plugins.h>
< 
< #define VERSION_NUM(major, minor, micro) (major * 1000000 + minor * 1000 + micro)
< #define FULL_GST_VERSION VERSION_NUM(GST_VERSION_MAJOR, GST_VERSION_MINOR, GST_VERSION_MICRO)
< 
< #if FULL_GST_VERSION >= VERSION_NUM(0,10,32)
< #include <gst/pbutils/encoding-profile.h>
< //#include <gst/base/gsttypefindhelper.h>
< #endif
< 
< 
< #ifdef NDEBUG
< #define CV_WARN(message)
< #else
< #define CV_WARN(message) fprintf(stderr, "warning: %s (%s:%d)\n", message, __FILE__, __LINE__)
< #endif
< 
< #if GST_VERSION_MAJOR == 0
< #define COLOR_ELEM "ffmpegcolorspace"
< #define COLOR_ELEM_NAME "ffmpegcsp"
< #elif FULL_GST_VERSION < VERSION_NUM(1,5,0)
< #define COLOR_ELEM "videoconvert"
< #define COLOR_ELEM_NAME COLOR_ELEM
< #else
< #define COLOR_ELEM "autovideoconvert"
< #define COLOR_ELEM_NAME COLOR_ELEM
< #endif
87,88d50
< void toFraction(double decimal, double &numerator, double &denominator);
< void handleMessage(GstElement * pipeline);
90,91c52
< 
< static cv::Mutex gst_initializer_mutex;
---
> #include "cap_gstreamer.hpp"
116,162d76
< /*!
<  * \brief The CvCapture_GStreamer class
<  * Use GStreamer to capture video
<  */
< class CvCapture_GStreamer : public CvCapture
< {
< public:
<     CvCapture_GStreamer() { init(); }
<     virtual ~CvCapture_GStreamer() { close(); }
< 
<     virtual bool open( int type, const char* filename );
<     virtual void close();
< 
<     virtual double getProperty(int);
<     virtual bool setProperty(int, double);
<     virtual bool grabFrame();
<     virtual IplImage* retrieveFrame(int);
< 
< protected:
<     void init();
<     bool reopen();
<     bool isPipelinePlaying();
<     void startPipeline();
<     void stopPipeline();
<     void restartPipeline();
<     void setFilter(const char* prop, int type, int v1, int v2 = 0);
<     void removeFilter(const char *filter);
<     static void newPad(GstElement *myelement,
<                        GstPad     *pad,
<                        gpointer    data);
<     GstElement*   pipeline;
<     GstElement*   uridecodebin;
<     GstElement*   v4l2src;
<     GstElement*   color;
<     GstElement*   sink;
< #if GST_VERSION_MAJOR > 0
<     GstSample*    sample;
<     GstMapInfo*   info;
< #endif
<     GstBuffer*    buffer;
<     GstCaps*      caps;
<     IplImage*     frame;
<     gint64        duration;
<     gint          width;
<     gint          height;
<     double        fps;
< };
175c89
< #if GST_VERSION_MAJOR > 0
---
> 
178c92
< #endif
---
> 
228,233d141
< #if GST_VERSION_MAJOR == 0
<     if(buffer)
<         gst_buffer_unref(buffer);
< 
<     buffer = gst_app_sink_pull_buffer(GST_APP_SINK(sink));
< #else
243d150
< #endif
264,266d170
< #if GST_VERSION_MAJOR == 0
<         GstCaps* buffer_caps = gst_buffer_get_caps(buffer);
< #else
268c172
< #endif
---
> 
282c186
< #if GST_VERSION_MAJOR > 0
---
> 
310d213
< #endif
323,325c226
< #if GST_VERSION_MAJOR == 0
<     frame->imageData = (char *)GST_BUFFER_DATA(buffer);
< #else
---
> 
337d237
< #endif
445,447d344
< #if GST_VERSION_MAJOR == 0
<             caps = gst_caps_new_simple("video/x-raw-rgb", prop, type, v1, NULL);
< #else
449d345
< #endif
453,455d348
< #if GST_VERSION_MAJOR == 0
<             caps = gst_caps_new_simple("video/x-raw-rgb", prop, type, v1, v2, NULL);
< #else
457d349
< #endif
462d353
< #if GST_VERSION_MAJOR > 0
465d355
< #endif
473d362
< #if GST_VERSION_MAJOR > 0
475d363
< #endif
492d379
< #if GST_VERSION_MAJOR > 0
495d381
< #endif
519d404
<         //fprintf(stderr, "Gstreamer: no pad named sink\n");
558,572c443,520
< bool CvCapture_GStreamer::open( int type, const char* filename )
< {
<     CV_FUNCNAME("cvCaptureFromCAM_GStreamer");
< 
<     __BEGIN__;
< 
<     gst_initializer::init();
< 
<     bool file = false;
<     bool stream = false;
<     bool manualpipeline = false;
<     char *uri = NULL;
<     uridecodebin = NULL;
<     GstElementFactory * testfac;
<     GstStateChangeReturn status;
---
> bool CvCapture_GStreamer::open(int type,
>   const char * filename) {
>   CV_FUNCNAME("cvCaptureFromCAM_GStreamer");
> 
>   __BEGIN__;
> 
>   gst_initializer::init();
> 
>   bool file = false;
>   bool stream = false;
>   bool manualpipeline = false;
>   char * uri = NULL;
>   uridecodebin = NULL;
>   GstElementFactory * testfac;
>   GstStateChangeReturn status;
> 
>   int cameraID = -1;
>   if (type == CV_CAP_GSTREAMER_V4L ||
>     type == CV_CAP_GSTREAMER_V4L2) {
>     cameraID = static_cast < int > (reinterpret_cast < intptr_t > (filename));
>   }
> 
>   std::stringstream stdstream;
>   std::string stdfilename;
> 
>   if (type == CV_CAP_GSTREAMER_V4L) {
>     testfac = gst_element_factory_find("v4lsrc");
>     if (!testfac) {
>       return false;
>     }
>     g_object_unref(G_OBJECT(testfac));
> 
>     stdstream << "v4lsrc device=/dev/video" << cameraID << " ! " << COLOR_ELEM << " ! appsink";
>     stdfilename = stdstream.str();
>     filename = stdfilename.c_str();
>   } else if (type == CV_CAP_GSTREAMER_V4L2) {
>     testfac = gst_element_factory_find("v4l2src");
>     if (!testfac) {
>       return false;
>     }
>     g_object_unref(G_OBJECT(testfac));
> 
>     stdstream << "v4l2src device=/dev/video" << cameraID << " ! " << COLOR_ELEM << " ! appsink";
>     stdfilename = stdstream.str();
>     //printf("STD FILENAME: %s\n", stdfilename.c_str());
>     //printf("COLOR ELEM: %s\n", COLOR_ELEM);
>     filename = stdfilename.c_str();
>     //printf("FILENAME: %s\n", filename);
>   }
> 
>   // test if we have a valid uri. If so, open it with an uridecodebin
>   // else, we might have a file or a manual pipeline.
>   // if gstreamer cannot parse the manual pipeline, we assume we were given and
>   // ordinary file path.
>   if (!gst_uri_is_valid(filename)) {
>     uri = realpath(filename, NULL);
>     //printf("filename: %s\n", filename);
>     stream = false;
>     if (uri) {
>       uri = g_filename_to_uri(uri, NULL, NULL);
>       printf("URI2: %s\n", uri);
>       if (uri) {
>         file = true;
>       } else {
>         CV_WARN("GStreamer: Error opening file\n");
>         close();
>         return false;
>       }
>     } else {
>       GError * err = NULL;
>       uridecodebin = gst_parse_launch(filename, & err);
>       if (!uridecodebin) {
>         printf("GStreamer: Error opening bin: %s\n", err -> message);
>         fprintf(stderr, "GStreamer: Error opening bin: %s\n", err -> message);
>         return false;
>       } else {
>         printf("GStreamer succesfully opened bin\n");
>       }
574,578c522,523
<     int cameraID = -1;
<     if (type == CV_CAP_GSTREAMER_V4L ||
<             type == CV_CAP_GSTREAMER_V4L2)
<     {
<         cameraID = static_cast<int>(reinterpret_cast<intptr_t>(filename));
---
>       stream = true;
>       manualpipeline = true;
579a525,561
>   } else {
>     stream = true;
>     uri = g_strdup(filename);
>   }
> 
>   bool element_from_uri = false;
>   if (!uridecodebin) {
>     // At this writing, the v4l2 element (and maybe others too) does not support caps renegotiation.
>     // This means that we cannot use an uridecodebin when dealing with v4l2, since setting
>     // capture properties will not work.
>     // The solution (probably only until gstreamer 1.2) is to make an element from uri when dealing with v4l2.
>     gchar * protocol = gst_uri_get_protocol(uri);
>     printf("PROTOCOL: %s\n", protocol);
>     if (!strcasecmp(protocol, "v4l2")) {
>       uridecodebin = gst_element_make_from_uri(GST_URI_SRC, uri, "src", NULL);
>       element_from_uri = true;
>     } else {
>       uridecodebin = gst_element_factory_make("uridecodebin", NULL);
>       g_object_set(G_OBJECT(uridecodebin), "uri", uri, NULL);
>     }
>     g_free(protocol);
> 
>     if (!uridecodebin) {
>       //fprintf(stderr, "GStreamer: Error opening bin: %s\n", err->message);
>       close();
>       return false;
>     }
>   }
> 
>   if (manualpipeline) {
>     printf ("using manual pipeline\n");
>     GstIterator * it = gst_bin_iterate_elements(GST_BIN(uridecodebin));
> 
>     GstElement * element = NULL;
>     gboolean done = false;
>     gchar * name = NULL;
>     GValue value = G_VALUE_INIT;
581,590c563,576
<     std::stringstream stdstream;
<     std::string stdfilename;
< 
<     if (type == CV_CAP_GSTREAMER_V4L)
<     {
<         testfac = gst_element_factory_find("v4lsrc");
<         if (!testfac){
<             return false;
<         }
<         g_object_unref(G_OBJECT(testfac));
---
>     while (!done) {
>       switch (gst_iterator_next(it, & value)) {
>       case GST_ITERATOR_OK:
>         element = GST_ELEMENT(g_value_get_object( & value));
>         name = gst_element_get_name(element);
>         if (name) {
>           if (strstr(name, "opencvsink") != NULL || strstr(name, "appsink") != NULL) {
>             sink = GST_ELEMENT(gst_object_ref(element));
>           } else if (strstr(name, COLOR_ELEM_NAME) != NULL) {
>             color = GST_ELEMENT(gst_object_ref(element));
>           } else if (strstr(name, "v4l") != NULL) {
>             v4l2src = GST_ELEMENT(gst_object_ref(element));
>           }
>           g_free(name);
592,600c578
<         stdstream << "v4lsrc device=/dev/video" << cameraID << " ! " << COLOR_ELEM << " ! appsink";
<         stdfilename = stdstream.str();
<         filename = stdfilename.c_str();
<     }
<     else if (type == CV_CAP_GSTREAMER_V4L2)
<     {
<         testfac = gst_element_factory_find("v4l2src");
<         if (!testfac){
<             return false;
---
>           done = sink && color && v4l2src;
602c580
<         g_object_unref(G_OBJECT(testfac));
---
>         g_value_unset( & value);
604,606c582,590
<         stdstream << "v4l2src device=/dev/video" << cameraID << " ! " << COLOR_ELEM << " ! appsink";
<         stdfilename = stdstream.str();
<         filename = stdfilename.c_str();
---
>         break;
>       case GST_ITERATOR_RESYNC:
>         gst_iterator_resync(it);
>         break;
>       case GST_ITERATOR_ERROR:
>       case GST_ITERATOR_DONE:
>         done = TRUE;
>         break;
>       }
607a592
>     gst_iterator_free(it);
609,648c594,618
< 
<     // test if we have a valid uri. If so, open it with an uridecodebin
<     // else, we might have a file or a manual pipeline.
<     // if gstreamer cannot parse the manual pipeline, we assume we were given and
<     // ordinary file path.
<     if(!gst_uri_is_valid(filename))
<     {
<         uri = realpath(filename, NULL);
<         stream = false;
<         if(uri)
<         {
<             uri = g_filename_to_uri(uri, NULL, NULL);
<             if(uri)
<             {
<                 file = true;
<             }
<             else
<             {
<                 CV_WARN("GStreamer: Error opening file\n");
<                 close();
<                 return false;
<             }
<         }
<         else
<         {
<             GError *err = NULL;
<             uridecodebin = gst_parse_launch(filename, &err);
<             if(!uridecodebin)
<             {
<                 fprintf(stderr, "GStreamer: Error opening bin: %s\n", err->message);
<                 return false;
<             }
<             stream = true;
<             manualpipeline = true;
<         }
<     }
<     else
<     {
<         stream = true;
<         uri = g_strdup(filename);
---
>     if (!sink) {
>       CV_ERROR(CV_StsError, "GStreamer: cannot find appsink in manual pipeline\n");
>       return false;
>     }
> 
>     pipeline = uridecodebin;
>     printf ("set manual pipeline\n");
>   } else {
>     pipeline = gst_pipeline_new(NULL);
>     // videoconvert (in 0.10: ffmpegcolorspace, in 1.x autovideoconvert)
>     //automatically selects the correct colorspace conversion based on caps.
>     color = gst_element_factory_make(COLOR_ELEM, NULL);
>     sink = gst_element_factory_make("appsink", NULL);
> 
>     gst_bin_add_many(GST_BIN(pipeline), uridecodebin, color, sink, NULL);
> 
>     if (element_from_uri) {
>       if (!gst_element_link(uridecodebin, color)) {
>         CV_ERROR(CV_StsError, "GStreamer: cannot link color -> sink\n");
>         gst_object_unref(pipeline);
>         pipeline = NULL;
>         return false;
>       }
>     } else {
>       g_signal_connect(uridecodebin, "pad-added", G_CALLBACK(newPad), color);
651,680c621,659
<     bool element_from_uri = false;
<     if(!uridecodebin)
<     {
<         // At this writing, the v4l2 element (and maybe others too) does not support caps renegotiation.
<         // This means that we cannot use an uridecodebin when dealing with v4l2, since setting
<         // capture properties will not work.
<         // The solution (probably only until gstreamer 1.2) is to make an element from uri when dealing with v4l2.
<         gchar * protocol = gst_uri_get_protocol(uri);
<         if (!strcasecmp(protocol , "v4l2"))
<         {
< #if GST_VERSION_MAJOR == 0
<             uridecodebin = gst_element_make_from_uri(GST_URI_SRC, uri, "src");
< #else
<             uridecodebin = gst_element_make_from_uri(GST_URI_SRC, uri, "src", NULL);
< #endif
<             element_from_uri = true;
<         }
<         else
<         {
<             uridecodebin = gst_element_factory_make("uridecodebin", NULL);
<             g_object_set(G_OBJECT(uridecodebin), "uri", uri, NULL);
<         }
<         g_free(protocol);
< 
<         if(!uridecodebin)
<         {
<             //fprintf(stderr, "GStreamer: Error opening bin: %s\n", err->message);
<             close();
<             return false;
<         }
---
>     if (!gst_element_link(color, sink)) {
>       CV_ERROR(CV_StsError, "GStreamer: cannot link color -> sink\n");
>       gst_object_unref(pipeline);
>       pipeline = NULL;
>       return false;
>     }
>   }
> 
>   //TODO: is 1 single buffer really high enough?
>   gst_app_sink_set_max_buffers(GST_APP_SINK(sink), 1);
>   gst_app_sink_set_drop(GST_APP_SINK(sink), stream);
> 
>   //do not emit signals: all calls will be synchronous and blocking
>   gst_app_sink_set_emit_signals(GST_APP_SINK(sink), 0);
> 
>   // support 1 and 3 channel 8 bit data, as well as bayer (also  1 channel, 8bit)
>   //caps = gst_caps_from_string("video/x-raw, format=(string){BGR, GRAY8}; video/x-bayer,format=(string){rggb,bggr,grbg,gbrg}");
>   caps = gst_caps_from_string("video/x-raw,format=(string)BGR");
> 
>   gst_app_sink_set_caps(GST_APP_SINK(sink), caps);
>   gst_caps_unref(caps);
>   printf ("set caps\n");
>   {
>     status = gst_element_set_state(GST_ELEMENT(pipeline),
>       file ? GST_STATE_PAUSED : GST_STATE_PLAYING);
> 
>     printf ("pipeline status: %d\n", status);
> 
>     if (status == GST_STATE_CHANGE_ASYNC) {
>       // wait for status update
>       status = gst_element_get_state(pipeline, NULL, NULL, GST_CLOCK_TIME_NONE);
>       printf ("pipeline status update recieved: %d\n", status);
>     }
>     if (status == GST_STATE_CHANGE_FAILURE) {
>       handleMessage(pipeline);
>       gst_object_unref(pipeline);
>       pipeline = NULL;
>       CV_ERROR(CV_StsError, "GStreamer: unable to start pipeline\n");
>       return false;
683,685d661
<     if (manualpipeline)
<     {
<         GstIterator *it = gst_bin_iterate_elements(GST_BIN(uridecodebin));
687,692d662
<         GstElement *element = NULL;
<         gboolean done = false;
<         gchar* name = NULL;
< #if GST_VERSION_MAJOR > 0
<         GValue value = G_VALUE_INIT;
< #endif
694,739c664
<         while (!done)
<         {
< #if GST_VERSION_MAJOR > 0
<             switch (gst_iterator_next (it, &value))
<             {
<             case GST_ITERATOR_OK:
<                 element = GST_ELEMENT (g_value_get_object (&value));
< #else
<             switch (gst_iterator_next (it, (gpointer *)&element))
<             {
<             case GST_ITERATOR_OK:
< #endif
<                 name = gst_element_get_name(element);
<                 if (name)
<                 {
<                     if (strstr(name, "opencvsink") != NULL || strstr(name, "appsink") != NULL)
<                     {
<                         sink = GST_ELEMENT ( gst_object_ref (element) );
<                     }
<                     else if (strstr(name, COLOR_ELEM_NAME) != NULL)
<                     {
<                         color = GST_ELEMENT ( gst_object_ref (element) );
<                     }
<                     else if (strstr(name, "v4l") != NULL)
<                     {
<                         v4l2src = GST_ELEMENT ( gst_object_ref (element) );
<                     }
<                     g_free(name);
< 
<                     done = sink && color && v4l2src;
<                 }
< #if GST_VERSION_MAJOR > 0
<                 g_value_unset (&value);
< #endif
< 
<                 break;
<             case GST_ITERATOR_RESYNC:
<                 gst_iterator_resync (it);
<                 break;
<             case GST_ITERATOR_ERROR:
<             case GST_ITERATOR_DONE:
<                 done = TRUE;
<                 break;
<             }
<         }
<         gst_iterator_free (it);
---
>     GstFormat format;
741,745c666
<         if (!sink)
<         {
<             CV_ERROR(CV_StsError, "GStreamer: cannot find appsink in manual pipeline\n");
<             return false;
<         }
---
>     format = GST_FORMAT_DEFAULT;
747c668,671
<         pipeline = uridecodebin;
---
>     if (!gst_element_query_duration(sink, format, & duration)) {
>       handleMessage(pipeline);
>       CV_WARN("GStreamer: unable to query duration of stream");
>       duration = -1;
749,755d672
<     else
<     {
<         pipeline = gst_pipeline_new(NULL);
<         // videoconvert (in 0.10: ffmpegcolorspace, in 1.x autovideoconvert)
<         //automatically selects the correct colorspace conversion based on caps.
<         color = gst_element_factory_make(COLOR_ELEM, NULL);
<         sink = gst_element_factory_make("appsink", NULL);
757c674,676
<         gst_bin_add_many(GST_BIN(pipeline), uridecodebin, color, sink, NULL);
---
>     GstPad * pad = gst_element_get_static_pad(color, "src");
>     GstCaps * buffer_caps = gst_pad_get_current_caps(pad);
>     const GstStructure * structure = gst_caps_get_structure(buffer_caps, 0);
759,772c678,681
<         if(element_from_uri)
<         {
<             if(!gst_element_link(uridecodebin, color))
<             {
<                 CV_ERROR(CV_StsError, "GStreamer: cannot link color -> sink\n");
<                 gst_object_unref(pipeline);
<                 pipeline = NULL;
<                 return false;
<             }
<         }
<         else
<         {
<             g_signal_connect(uridecodebin, "pad-added", G_CALLBACK(newPad), color);
<         }
---
>     printf ("PAD: %s\nBUFFER CAPS: %s\nSTRUCTURE: %s\n", 
>         "testing",
>         gst_caps_to_string (buffer_caps),
>         gst_structure_to_string (structure));
774,780c683,684
<         if(!gst_element_link(color, sink))
<         {
<             CV_ERROR(CV_StsError, "GStreamer: cannot link color -> sink\n");
<             gst_object_unref(pipeline);
<             pipeline = NULL;
<             return false;
<         }
---
>     if (!gst_structure_get_int(structure, "width", & width)) {
>       CV_WARN("Cannot query video width\n");
783,850c687,689
<     //TODO: is 1 single buffer really high enough?
<     gst_app_sink_set_max_buffers (GST_APP_SINK(sink), 1);
<     gst_app_sink_set_drop (GST_APP_SINK(sink), stream);
<     //do not emit signals: all calls will be synchronous and blocking
<     gst_app_sink_set_emit_signals (GST_APP_SINK(sink), 0);
< 
< #if GST_VERSION_MAJOR == 0
<     caps = gst_caps_new_simple("video/x-raw-rgb",
<                                "bpp",        G_TYPE_INT, 24,
<                                "red_mask",   G_TYPE_INT, 0x0000FF,
<                                "green_mask", G_TYPE_INT, 0x00FF00,
<                                "blue_mask",  G_TYPE_INT, 0xFF0000,
<                                NULL);
< #else
<     // support 1 and 3 channel 8 bit data, as well as bayer (also  1 channel, 8bit)
<     caps = gst_caps_from_string("video/x-raw, format=(string){BGR, GRAY8}; video/x-bayer,format=(string){rggb,bggr,grbg,gbrg}");
< #endif
<     gst_app_sink_set_caps(GST_APP_SINK(sink), caps);
<     gst_caps_unref(caps);
< 
<     {
<         status = gst_element_set_state(GST_ELEMENT(pipeline),
<                                        file ? GST_STATE_PAUSED : GST_STATE_PLAYING);
<         if (status == GST_STATE_CHANGE_ASYNC)
<         {
<             // wait for status update
<             status = gst_element_get_state(pipeline, NULL, NULL, GST_CLOCK_TIME_NONE);
<         }
<         if (status == GST_STATE_CHANGE_FAILURE)
<         {
<             handleMessage(pipeline);
<             gst_object_unref(pipeline);
<             pipeline = NULL;
<             CV_ERROR(CV_StsError, "GStreamer: unable to start pipeline\n");
<             return false;
<         }
< 
<         GstFormat format;
< 
<         format = GST_FORMAT_DEFAULT;
< #if GST_VERSION_MAJOR == 0
<         if(!gst_element_query_duration(sink, &format, &duration))
< #else
<         if(!gst_element_query_duration(sink, format, &duration))
< #endif
<         {
<             handleMessage(pipeline);
<             CV_WARN("GStreamer: unable to query duration of stream");
<             duration = -1;
<         }
< 
<         GstPad* pad = gst_element_get_static_pad(color, "src");
< #if GST_VERSION_MAJOR == 0
<         GstCaps* buffer_caps = gst_pad_get_caps(pad);
< #else
<         GstCaps* buffer_caps = gst_pad_get_current_caps(pad);
< #endif
<         const GstStructure *structure = gst_caps_get_structure (buffer_caps, 0);
< 
<         if (!gst_structure_get_int (structure, "width", &width))
<         {
<             CV_WARN("Cannot query video width\n");
<         }
< 
<         if (!gst_structure_get_int (structure, "height", &height))
<         {
<             CV_WARN("Cannot query video heigth\n");
<         }
---
>     if (!gst_structure_get_int(structure, "height", & height)) {
>       CV_WARN("Cannot query video heigth\n");
>     }
852,856c691,694
<         gint num = 0, denom=1;
<         if(!gst_structure_get_fraction(structure, "framerate", &num, &denom))
<         {
<             CV_WARN("Cannot query video fps\n");
<         }
---
>     gint num = 0, denom = 1;
>     if (!gst_structure_get_fraction(structure, "framerate", & num, & denom)) {
>       CV_WARN("Cannot query video fps\n");
>     }
858c696
<         fps = (double)num/(double)denom;
---
>     fps = (double) num / (double) denom;
860c698
<          // GST_DEBUG_BIN_TO_DOT_FILE(GST_BIN(pipeline), GST_DEBUG_GRAPH_SHOW_ALL, "pipeline")
---
>     // GST_DEBUG_BIN_TO_DOT_FILE(GST_BIN(pipeline), GST_DEBUG_GRAPH_SHOW_ALL, "pipeline")
862,863c700,701
<         stopPipeline();
<     }
---
>     stopPipeline();
>   }
865c703
<     __END__;
---
>   __END__;
867c705
<     return true;
---
>   return true;
885,887d722
< #if GST_VERSION_MAJOR == 0
< #define FORMAT &format
< #else
889d723
< #endif
1098,1106d931
< /*!
<  * \brief The CvVideoWriter_GStreamer class
<  * Use Gstreamer to write video
<  */
< class CvVideoWriter_GStreamer : public CvVideoWriter
< {
< public:
<     CvVideoWriter_GStreamer() { init(); }
<     virtual ~CvVideoWriter_GStreamer() { close(); }
1108,1124d932
<     virtual bool open( const char* filename, int fourcc,
<                        double fps, CvSize frameSize, bool isColor );
<     virtual void close();
<     virtual bool writeFrame( const IplImage* image );
< protected:
<     void init();
<     const char* filenameToMimetype(const char* filename);
<     GstElement* pipeline;
<     GstElement* source;
<     GstElement* encodebin;
<     GstElement* file;
< 
<     GstBuffer* buffer;
<     int input_pix_fmt;
<     int num_frames;
<     double framerate;
< };
1284d1091
< #if FULL_GST_VERSION >= VERSION_NUM(0,10,32)
1288d1094
< #endif
1295,1299d1100
< #if GST_VERSION_MAJOR == 0
<     GstElement* splitter = NULL;
<     GstElement* combiner = NULL;
< #endif
< 
1307a1109,1110
>     //printf ("filename: %s\nerr: %s\ncodebin: %s\n\n", filename, err != NULL ? err -> message : "no error", encodebin);
> 
1310,1316c1113,1114
< #if GST_VERSION_MAJOR == 0
<         it = gst_bin_iterate_sources(GST_BIN(encodebin));
<         if(gst_iterator_next(it, (gpointer *)&source) != GST_ITERATOR_OK) {
<             CV_ERROR(CV_StsError, "GStreamer: cannot find appsink in manual pipeline\n");
<             return false;
<         }
< #else
---
>         printf ("found manual pipeline\n");
> 
1350d1147
< #endif
1381d1177
< #if FULL_GST_VERSION >= VERSION_NUM(0,10,32)
1388d1183
< #endif
1393d1187
< #if FULL_GST_VERSION >= VERSION_NUM(0,10,32)
1395c1189
< #endif
---
> 
1406,1412d1199
< #if GST_VERSION_MAJOR == 0
<         caps = gst_video_format_new_caps(GST_VIDEO_FORMAT_BGR,
<                                          frameSize.width,
<                                          frameSize.height,
<                                          int(fps), 1,
<                                          1, 1);
< #else
1420,1422d1206
< 
< #endif
< 
1426d1209
< #if FULL_GST_VERSION >= VERSION_NUM(0,10,29)
1430,1436d1212
< #if GST_VERSION_MAJOR == 0
<         caps = gst_video_format_new_caps(GST_VIDEO_FORMAT_GRAY8,
<                                          frameSize.width,
<                                          frameSize.height,
<                                          int(fps), 1,
<                                          1, 1);
< #else
1444,1447d1219
< #endif
< #else
<         CV_Assert(!"Gstreamer 0.10.29 or newer is required for grayscale input");
< #endif
1449a1222,1224
>     printf ("Writer caps: %s\n", gst_caps_to_string (caps));
> 
> 
1458d1232
< 
1468,1524d1241
< #if GST_VERSION_MAJOR == 0
<     // HACK: remove streamsplitter and streamcombiner from
<     // encodebin pipeline to prevent early EOF event handling
<     // We always fetch BGR or gray-scale frames, so combiner->spliter
<     // endge in graph is useless.
<     it = gst_bin_iterate_recurse (GST_BIN(encodebin));
<     while (!done) {
<       switch (gst_iterator_next (it, (void**)&element)) {
<         case GST_ITERATOR_OK:
<           name = gst_element_get_name(element);
<           if (strstr(name, "streamsplitter"))
<             splitter = element;
<           else if (strstr(name, "streamcombiner"))
<             combiner = element;
<           break;
<         case GST_ITERATOR_RESYNC:
<           gst_iterator_resync (it);
<           break;
<         case GST_ITERATOR_ERROR:
<           done = true;
<           break;
<         case GST_ITERATOR_DONE:
<           done = true;
<           break;
<       }
<     }
< 
<     gst_iterator_free (it);
< 
<     if (splitter && combiner)
<     {
<         gst_element_unlink(splitter, combiner);
< 
<         GstPad* src  = gst_element_get_pad(combiner, "src");
<         GstPad* sink = gst_element_get_pad(combiner, "encodingsink");
< 
<         GstPad* srcPeer = gst_pad_get_peer(src);
<         GstPad* sinkPeer = gst_pad_get_peer(sink);
< 
<         gst_pad_unlink(sinkPeer, sink);
<         gst_pad_unlink(src, srcPeer);
< 
<         gst_pad_link(sinkPeer, srcPeer);
< 
<         src = gst_element_get_pad(splitter, "encodingsrc");
<         sink = gst_element_get_pad(splitter, "sink");
< 
<         srcPeer = gst_pad_get_peer(src);
<         sinkPeer = gst_pad_get_peer(sink);
< 
<         gst_pad_unlink(sinkPeer, sink);
<         gst_pad_unlink(src, srcPeer);
< 
<         gst_pad_link(sinkPeer, srcPeer);
<     }
< #endif
< 
1567d1283
< #if FULL_GST_VERSION >= VERSION_NUM(0,10,29)
1573d1288
< #endif
1584,1594d1298
< #if GST_VERSION_MAJOR == 0
<     buffer = gst_buffer_try_new_and_alloc (size);
<     if (!buffer)
<     {
<         CV_ERROR(CV_StsBadSize, "Cannot create GStreamer buffer");
<     }
< 
<     memcpy(GST_BUFFER_DATA (buffer), (guint8*)image->imageData, size);
<     GST_BUFFER_DURATION(buffer) = duration;
<     GST_BUFFER_TIMESTAMP(buffer) = timestamp;
< #else
1603c1307
< #endif
---
> 
